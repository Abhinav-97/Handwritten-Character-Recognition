{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Convolution2D, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  create_model.ipynb  encode_data.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOCATION = \"/data/English/Hnd/Img/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "image_size_flat = img_height*img_width\n",
    "\n",
    "img_shape = (img_height,img_width)\n",
    "\n",
    "num_channel = 1# for Gray scale\n",
    "\n",
    "num_classes = 62 # for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_argmax(folder_name):\n",
    "    index = int(re.search(\"Sample(.*)\", folder_name).group(1)) - 1\n",
    "    arr = np.zeros(num_classes)\n",
    "    arr[index] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_img2np(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_img2np2(path):\n",
    "    img = cv2.imread(path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_argmax(\"Sample006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    DATASET_LOCATION = \"/data/English/Hnd/Img/\"\n",
    "    hcr = {\"data\":[], \"labels\":[], \"cls\":[]}\n",
    "    for folder in glob.glob(DATASET_LOCATION + \"/*\"):\n",
    "        if os.path.isdir(folder):\n",
    "            for img_path in glob.glob(folder + '/*.png'):\n",
    "                hcr.get('data').append(cvt_img2np(img_path))\n",
    "                hcr.get(\"labels\").append(create_argmax(folder))\n",
    "                hcr.get(\"cls\").append(int(folder[-3:]) - 1)\n",
    "#     print(\"read completed\")\n",
    "    permutate = np.random.permutation(len(hcr.get('data')))\n",
    "    return {k1:v1[permutate] for k1, v1 in {k: np.array(v) for k, v in hcr.items()}.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == 9 and len(cls_true) == 9\n",
    "    \n",
    "    fig, axes = plt.subplots(3,3,figsize=(10,10))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        ax.imshow(images[i], cmap=\"binary\")\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True {0}, Pred {1}\".format(cls_true[i], cls_pred[i])\n",
    "    \n",
    "        ax.set_xlabel(xlabel)\n",
    "    \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcr = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = hcr.get(\"data\")[3000:3009]\n",
    "cls_true = hcr.get(\"cls\")[3000:3009]\n",
    "\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hcr = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcr[\"labels\"][90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hcr[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.reshape((3410,1,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(\"float32\")\n",
    "data = data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hcr[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3410, 1, 32, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 16\n",
    "kernel_size = (3,3)\n",
    "batch_size = 32\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convolution2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "conv_model = Sequential()\n",
    "\n",
    "conv_model.add(Conv2D(filters, (3,3), padding=\"same\", input_shape=(1,32,32)))\n",
    "conv_model.add(Activation(\"relu\"))\n",
    "\n",
    "conv_model.add(Conv2D(filters, kernel_size=(3,3), padding=\"same\"))\n",
    "conv_model.add(Activation(\"relu\"))\n",
    "conv_model.add(MaxPooling2D(pool_size=(2,2), dim_ordering=\"th\"))\n",
    "conv_model.add(Dropout(0.2))\n",
    "\n",
    "conv_model.add(Conv2D(filters, kernel_size=(3,3), padding=\"same\"))\n",
    "conv_model.add(Activation(\"relu\"))\n",
    "conv_model.add(MaxPooling2D(pool_size=(2,2), dim_ordering=\"th\"))\n",
    "conv_model.add(Dropout(0.2))\n",
    "\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(128))\n",
    "conv_model.add(Activation(\"relu\"))\n",
    "\n",
    "# conv_model.add(Dropout(0.2))\n",
    "conv_model.add(Dense(num_classes))\n",
    "conv_model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 1, 32, 16)         4624      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 32, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 1, 32, 16)         2320      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 32, 16)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 16, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 16, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 1, 16, 16)         1168      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 16, 16)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 62)                7998      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 62)                0         \n",
      "=================================================================\n",
      "Total params: 24,430\n",
      "Trainable params: 24,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2898 samples, validate on 512 samples\n",
      "Epoch 1/25\n",
      "2898/2898 [==============================] - 1s 288us/step - loss: 2.5208 - acc: 0.3043 - val_loss: 2.4535 - val_acc: 0.3262\n",
      "Epoch 2/25\n",
      "2898/2898 [==============================] - 1s 271us/step - loss: 2.4704 - acc: 0.3133 - val_loss: 2.3671 - val_acc: 0.3730\n",
      "Epoch 3/25\n",
      "2898/2898 [==============================] - 1s 269us/step - loss: 2.4463 - acc: 0.3216 - val_loss: 2.3486 - val_acc: 0.3770\n",
      "Epoch 4/25\n",
      "2898/2898 [==============================] - 1s 264us/step - loss: 2.3931 - acc: 0.3309 - val_loss: 2.3510 - val_acc: 0.3574\n",
      "Epoch 5/25\n",
      "2898/2898 [==============================] - 1s 260us/step - loss: 2.3621 - acc: 0.3285 - val_loss: 2.3368 - val_acc: 0.3477\n",
      "Epoch 6/25\n",
      "2898/2898 [==============================] - 1s 263us/step - loss: 2.3323 - acc: 0.3392 - val_loss: 2.2628 - val_acc: 0.3906\n",
      "Epoch 7/25\n",
      "2898/2898 [==============================] - 1s 267us/step - loss: 2.3292 - acc: 0.3371 - val_loss: 2.2724 - val_acc: 0.3672\n",
      "Epoch 8/25\n",
      "2898/2898 [==============================] - 1s 266us/step - loss: 2.2683 - acc: 0.3475 - val_loss: 2.2043 - val_acc: 0.4062\n",
      "Epoch 9/25\n",
      "2898/2898 [==============================] - 1s 276us/step - loss: 2.2498 - acc: 0.3554 - val_loss: 2.2047 - val_acc: 0.3809\n",
      "Epoch 10/25\n",
      "2898/2898 [==============================] - 1s 268us/step - loss: 2.2324 - acc: 0.3516 - val_loss: 2.1614 - val_acc: 0.4043\n",
      "Epoch 11/25\n",
      "2898/2898 [==============================] - 1s 262us/step - loss: 2.1929 - acc: 0.3634 - val_loss: 2.1503 - val_acc: 0.4062\n",
      "Epoch 12/25\n",
      "2898/2898 [==============================] - 1s 269us/step - loss: 2.1954 - acc: 0.3647 - val_loss: 2.1845 - val_acc: 0.4062\n",
      "Epoch 13/25\n",
      "2898/2898 [==============================] - 1s 256us/step - loss: 2.1752 - acc: 0.3703 - val_loss: 2.1129 - val_acc: 0.4102\n",
      "Epoch 14/25\n",
      "2898/2898 [==============================] - 1s 265us/step - loss: 2.1205 - acc: 0.3837 - val_loss: 2.1111 - val_acc: 0.4316\n",
      "Epoch 15/25\n",
      "2898/2898 [==============================] - 1s 267us/step - loss: 2.1024 - acc: 0.3775 - val_loss: 2.0648 - val_acc: 0.4180\n",
      "Epoch 16/25\n",
      "2898/2898 [==============================] - 1s 259us/step - loss: 2.1013 - acc: 0.3841 - val_loss: 2.0409 - val_acc: 0.4316\n",
      "Epoch 17/25\n",
      "2898/2898 [==============================] - 1s 257us/step - loss: 2.0724 - acc: 0.3892 - val_loss: 2.1618 - val_acc: 0.4004\n",
      "Epoch 18/25\n",
      "2898/2898 [==============================] - 1s 265us/step - loss: 2.0780 - acc: 0.3813 - val_loss: 2.0108 - val_acc: 0.4453\n",
      "Epoch 19/25\n",
      "2898/2898 [==============================] - 1s 264us/step - loss: 2.0583 - acc: 0.3916 - val_loss: 2.0480 - val_acc: 0.4355\n",
      "Epoch 20/25\n",
      "2898/2898 [==============================] - 1s 263us/step - loss: 2.0730 - acc: 0.3934 - val_loss: 2.0217 - val_acc: 0.4238\n",
      "Epoch 21/25\n",
      "2898/2898 [==============================] - 1s 251us/step - loss: 2.0151 - acc: 0.4099 - val_loss: 1.9621 - val_acc: 0.4512\n",
      "Epoch 22/25\n",
      "2898/2898 [==============================] - 1s 260us/step - loss: 2.0299 - acc: 0.4044 - val_loss: 2.0844 - val_acc: 0.4023\n",
      "Epoch 23/25\n",
      "2898/2898 [==============================] - 1s 268us/step - loss: 1.9713 - acc: 0.4044 - val_loss: 1.9702 - val_acc: 0.4297\n",
      "Epoch 24/25\n",
      "2898/2898 [==============================] - 1s 260us/step - loss: 1.9378 - acc: 0.4089 - val_loss: 1.9779 - val_acc: 0.4180\n",
      "Epoch 25/25\n",
      "2898/2898 [==============================] - 1s 253us/step - loss: 1.9492 - acc: 0.4079 - val_loss: 2.0295 - val_acc: 0.4141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcacd68a3c8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape((3410,1,32,32))\n",
    "conv_model.fit(data, hcr[\"labels\"], epochs=25, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape((3410,1024 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(1024,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(256, input_shape=(1024,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 62)                15934     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 62)                0         \n",
      "=================================================================\n",
      "Total params: 672,062\n",
      "Trainable params: 672,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2898 samples, validate on 512 samples\n",
      "Epoch 1/40\n",
      "2898/2898 [==============================] - 1s 365us/step - loss: 2.0498 - acc: 0.4382 - val_loss: 2.5525 - val_acc: 0.3516\n",
      "Epoch 2/40\n",
      "2898/2898 [==============================] - 1s 382us/step - loss: 2.0019 - acc: 0.4486 - val_loss: 2.5695 - val_acc: 0.3457\n",
      "Epoch 3/40\n",
      "2898/2898 [==============================] - 1s 363us/step - loss: 1.9561 - acc: 0.4517 - val_loss: 2.6323 - val_acc: 0.3340\n",
      "Epoch 4/40\n",
      "2898/2898 [==============================] - 1s 369us/step - loss: 1.9598 - acc: 0.4513 - val_loss: 2.5023 - val_acc: 0.3457\n",
      "Epoch 5/40\n",
      "2898/2898 [==============================] - 1s 363us/step - loss: 1.8890 - acc: 0.4662 - val_loss: 2.5192 - val_acc: 0.3320\n",
      "Epoch 6/40\n",
      "2898/2898 [==============================] - 1s 367us/step - loss: 1.8551 - acc: 0.4769 - val_loss: 2.4500 - val_acc: 0.3750\n",
      "Epoch 7/40\n",
      "2898/2898 [==============================] - 1s 370us/step - loss: 1.8654 - acc: 0.4772 - val_loss: 2.4514 - val_acc: 0.3652\n",
      "Epoch 8/40\n",
      "2898/2898 [==============================] - 1s 403us/step - loss: 1.7983 - acc: 0.4962 - val_loss: 2.4585 - val_acc: 0.3711\n",
      "Epoch 9/40\n",
      "2898/2898 [==============================] - 1s 370us/step - loss: 1.7982 - acc: 0.4917 - val_loss: 2.5234 - val_acc: 0.3535\n",
      "Epoch 10/40\n",
      "2898/2898 [==============================] - 1s 380us/step - loss: 1.7642 - acc: 0.4948 - val_loss: 2.4096 - val_acc: 0.3984\n",
      "Epoch 11/40\n",
      "2898/2898 [==============================] - 1s 373us/step - loss: 1.7139 - acc: 0.5062 - val_loss: 2.4097 - val_acc: 0.3848\n",
      "Epoch 12/40\n",
      "2898/2898 [==============================] - 1s 372us/step - loss: 1.6955 - acc: 0.5079 - val_loss: 2.4680 - val_acc: 0.4121\n",
      "Epoch 13/40\n",
      "2898/2898 [==============================] - 1s 377us/step - loss: 1.6678 - acc: 0.5242 - val_loss: 2.4381 - val_acc: 0.4043\n",
      "Epoch 14/40\n",
      "2898/2898 [==============================] - 1s 372us/step - loss: 1.6484 - acc: 0.5242 - val_loss: 2.3588 - val_acc: 0.4102\n",
      "Epoch 15/40\n",
      "2898/2898 [==============================] - 1s 371us/step - loss: 1.5894 - acc: 0.5324 - val_loss: 2.5877 - val_acc: 0.3535\n",
      "Epoch 16/40\n",
      "2898/2898 [==============================] - 1s 376us/step - loss: 1.5916 - acc: 0.5293 - val_loss: 2.4671 - val_acc: 0.3965\n",
      "Epoch 17/40\n",
      "2898/2898 [==============================] - 1s 365us/step - loss: 1.5918 - acc: 0.5393 - val_loss: 2.5481 - val_acc: 0.3984\n",
      "Epoch 18/40\n",
      "2898/2898 [==============================] - 1s 373us/step - loss: 1.5175 - acc: 0.5538 - val_loss: 2.4606 - val_acc: 0.3828\n",
      "Epoch 19/40\n",
      "2898/2898 [==============================] - 1s 370us/step - loss: 1.4935 - acc: 0.5556 - val_loss: 2.4703 - val_acc: 0.3906\n",
      "Epoch 20/40\n",
      "2898/2898 [==============================] - 1s 371us/step - loss: 1.4860 - acc: 0.5621 - val_loss: 2.3689 - val_acc: 0.4199\n",
      "Epoch 21/40\n",
      "2898/2898 [==============================] - 1s 364us/step - loss: 1.4575 - acc: 0.5690 - val_loss: 2.3995 - val_acc: 0.4219\n",
      "Epoch 22/40\n",
      "2898/2898 [==============================] - 1s 361us/step - loss: 1.4500 - acc: 0.5694 - val_loss: 2.3763 - val_acc: 0.4141\n",
      "Epoch 23/40\n",
      "2898/2898 [==============================] - 1s 366us/step - loss: 1.4115 - acc: 0.5804 - val_loss: 2.5182 - val_acc: 0.3965\n",
      "Epoch 24/40\n",
      "2898/2898 [==============================] - 1s 357us/step - loss: 1.4085 - acc: 0.5680 - val_loss: 2.4107 - val_acc: 0.4180\n",
      "Epoch 25/40\n",
      "2898/2898 [==============================] - 1s 366us/step - loss: 1.4048 - acc: 0.5814 - val_loss: 2.5906 - val_acc: 0.3809\n",
      "Epoch 26/40\n",
      "2898/2898 [==============================] - 1s 366us/step - loss: 1.3620 - acc: 0.5956 - val_loss: 2.4882 - val_acc: 0.3867\n",
      "Epoch 27/40\n",
      "2898/2898 [==============================] - 1s 358us/step - loss: 1.3706 - acc: 0.5856 - val_loss: 2.5170 - val_acc: 0.3809\n",
      "Epoch 28/40\n",
      "2898/2898 [==============================] - 1s 357us/step - loss: 1.3410 - acc: 0.6008 - val_loss: 2.4350 - val_acc: 0.3828\n",
      "Epoch 29/40\n",
      "2898/2898 [==============================] - 1s 382us/step - loss: 1.3213 - acc: 0.5942 - val_loss: 2.4510 - val_acc: 0.3887\n",
      "Epoch 30/40\n",
      "2898/2898 [==============================] - 1s 359us/step - loss: 1.2997 - acc: 0.6032 - val_loss: 2.4433 - val_acc: 0.4102\n",
      "Epoch 31/40\n",
      "2898/2898 [==============================] - 1s 376us/step - loss: 1.2769 - acc: 0.6177 - val_loss: 2.4633 - val_acc: 0.4141\n",
      "Epoch 32/40\n",
      "2898/2898 [==============================] - 1s 370us/step - loss: 1.2561 - acc: 0.6090 - val_loss: 2.6320 - val_acc: 0.3984\n",
      "Epoch 33/40\n",
      "2752/2898 [===========================>..] - ETA: 0s - loss: 1.2892 - acc: 0.6061"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3a2ff0f6795f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhcr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(data, hcr[\"labels\"], validation_split=0.15, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
